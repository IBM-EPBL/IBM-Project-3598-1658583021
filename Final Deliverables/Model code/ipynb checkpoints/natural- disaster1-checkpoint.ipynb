{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "brief-diploma",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user\\\\Downloads\\\\AI-Based-Natural-Disaster-Intensity-Analysis-using-IBM-Watson-Stdio-main\\\\AI-Based-Natural-Disaster-Intensity-Analysis-using-IBM-Watson-Stdio-main'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240ba219",
   "metadata": {},
   "source": [
    "# Inserting necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1880001b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\u001b[38;5;66;03m#used for numerical analysis\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;66;03m#open source used for both ML and DL for computation\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential \u001b[38;5;66;03m#it is a plain stack of layers\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m layers \u001b[38;5;66;03m#A layer consists of a tensor-in tensor-out computation function\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import numpy as np#used for numerical analysis\n",
    "import tensorflow #open source used for both ML and DL for computation\n",
    "from tensorflow.keras.models import Sequential #it is a plain stack of layers\n",
    "from tensorflow.keras import layers #A layer consists of a tensor-in tensor-out computation function\n",
    "#Dense layer is the regular deeply connected neural network layer\n",
    "from tensorflow.keras.layers import Dense,Flatten\n",
    "#Faltten-used fot flattening the input or change the dimension\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D #Convolutional layer\n",
    "#MaxPooling2D-for downsampling the image\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de4433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9266ab12",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tensorflow' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtensorflow\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39m__version__\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tensorflow' is not defined"
     ]
    }
   ],
   "source": [
    "tensorflow.keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8755ebc6",
   "metadata": {},
   "source": [
    "# Image Data Augumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2849cdf2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageDataGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#setting parameter for Image Data agumentation to the training data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_datagen \u001b[38;5;241m=\u001b[39m \u001b[43mImageDataGenerator\u001b[49m(rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m,shear_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,zoom_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m,horizontal_flip\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#Image Data agumentation to the testing data\u001b[39;00m\n\u001b[0;32m      4\u001b[0m test_datagen\u001b[38;5;241m=\u001b[39mImageDataGenerator(rescale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m255\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ImageDataGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "#setting parameter for Image Data agumentation to the training data\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "#Image Data agumentation to the testing data\n",
    "test_datagen=ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cc8750",
   "metadata": {},
   "source": [
    "# Loading our data and performing Data Augumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "commercial-audio",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ibm_boto3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbotocore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclient\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Config\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mibm_boto3\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# @hidden_cell\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# You might want to remove those credentials before you share the notebook.\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ibm_boto3'"
     ]
    }
   ],
   "source": [
    "\n",
    "import os, types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "\n",
    "if os.environ.get('RUNTIME_ENV_LOCATION_TYPE') == 'external':\n",
    "    endpoint_d6c4aa54985d4755b8f33ab78c4fe1f0 = 'https://s3.us.cloud-object-storage.appdomain.cloud'\n",
    "else:\n",
    "    endpoint_d6c4aa54985d4755b8f33ab78c4fe1f0 = 'https://s3.private.us.cloud-object-storage.appdomain.cloud'\n",
    "\n",
    "client_d6c4aa54985d4755b8f33ab78c4fe1f0 = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='k1ICcSyubCBRkuMzExqnzzFWzxk_udmE35sGXYL5wkNc',\n",
    "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url=endpoint_d6c4aa54985d4755b8f33ab78c4fe1f0)\n",
    "\n",
    "streaming_body_1 = client_d6c4aa54985d4755b8f33ab78c4fe1f0.get_object(Bucket='naturaldisaster-donotdelete-pr-aj3prbxphtojo0', Key='dataset.zip')['Body']\n",
    "\n",
    "# Your data file was loaded into a botocore.response.StreamingBody object.\n",
    "# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n",
    "# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n",
    "# pandas documentation: http://pandas.pydata.org/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "lyric-seventh",
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "import zipfile\n",
    "unzip = zipfile.ZipFile(BytesIO(streaming_body_1.read()),'r')\n",
    "file_paths = unzip.namelist()\n",
    "for path in file_paths:\n",
    "    unzip.extract(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dense-worcester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wsuser/work'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "humanitarian-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "filenames = os.listdir('/home/wsuser/work/dataset/train_set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7504ebdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 742 images belonging to 4 classes.\n",
      "Found 198 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "#performing data agumentation to train data\n",
    "x_train = train_datagen.flow_from_directory(r'/home/wsuser/work/dataset/train_set',target_size=(64, 64),batch_size=5,\n",
    "                                            color_mode='rgb',class_mode='categorical')\n",
    "#performing data agumentation to test data\n",
    "x_test = test_datagen.flow_from_directory(r'/home/wsuser/work/dataset/test_set',target_size=(64, 64),batch_size=5,\n",
    "                                            color_mode='rgb',class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23e9b190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cyclone': 0, 'Earthquake': 1, 'Flood': 2, 'Wildfire': 3}\n"
     ]
    }
   ],
   "source": [
    "print(x_train.class_indices)#checking the number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5d1bb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Cyclone1': 0, 'Earthquake1': 1, 'Flood1': 2, 'Wildfire1': 3}\n"
     ]
    }
   ],
   "source": [
    "print(x_test.class_indices)#checking the number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04edbb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 220, 1: 156, 2: 198, 3: 168})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter as c\n",
    "c(x_train .labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b844dc41",
   "metadata": {},
   "source": [
    "# Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f26121f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# First convolution layer and poolingo\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
    "# Second convolution layer and pooling\n",
    "classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "# input_shape is going to be the pooled feature maps from the previous convolution layer\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
    "\n",
    "# Flattening the layers\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Adding a fully connected layer\n",
    "classifier.add(Dense(units=128, activation='relu'))\n",
    "classifier.add(Dense(units=4, activation='softmax')) # softmax for more than 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a68921cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 29, 29, 32)        9248      \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 27, 27, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 11, 11, 32)        9248      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3872)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               495744    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 516       \n",
      "=================================================================\n",
      "Total params: 524,900\n",
      "Trainable params: 524,900\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()#summary of our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c3e5d7",
   "metadata": {},
   "source": [
    "# Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02810f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the CNN\n",
    "# categorical_crossentropy for more than 2\n",
    "classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d86c2c1",
   "metadata": {},
   "source": [
    "# Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08aef824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-24-386df932e001>:1: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/20\n",
      "149/149 [==============================] - 32s 217ms/step - loss: 1.1916 - accuracy: 0.4582 - val_loss: 1.0800 - val_accuracy: 0.5505\n",
      "Epoch 2/20\n",
      "149/149 [==============================] - 32s 213ms/step - loss: 1.0074 - accuracy: 0.5876 - val_loss: 1.1755 - val_accuracy: 0.5505\n",
      "Epoch 3/20\n",
      "149/149 [==============================] - 31s 211ms/step - loss: 0.8887 - accuracy: 0.6146 - val_loss: 0.9522 - val_accuracy: 0.6465\n",
      "Epoch 4/20\n",
      "149/149 [==============================] - 31s 210ms/step - loss: 0.8046 - accuracy: 0.6685 - val_loss: 0.8259 - val_accuracy: 0.6566\n",
      "Epoch 5/20\n",
      "149/149 [==============================] - 31s 208ms/step - loss: 0.7213 - accuracy: 0.7291 - val_loss: 1.2338 - val_accuracy: 0.5556\n",
      "Epoch 6/20\n",
      "149/149 [==============================] - 31s 210ms/step - loss: 0.6916 - accuracy: 0.7237 - val_loss: 0.7315 - val_accuracy: 0.7273\n",
      "Epoch 7/20\n",
      "149/149 [==============================] - 31s 208ms/step - loss: 0.6020 - accuracy: 0.7588 - val_loss: 0.7086 - val_accuracy: 0.7323\n",
      "Epoch 8/20\n",
      "149/149 [==============================] - 31s 206ms/step - loss: 0.6151 - accuracy: 0.7615 - val_loss: 0.7183 - val_accuracy: 0.7222\n",
      "Epoch 9/20\n",
      "149/149 [==============================] - 31s 209ms/step - loss: 0.5500 - accuracy: 0.7776 - val_loss: 0.6641 - val_accuracy: 0.7525\n",
      "Epoch 10/20\n",
      "149/149 [==============================] - 31s 209ms/step - loss: 0.4813 - accuracy: 0.8167 - val_loss: 0.8024 - val_accuracy: 0.7020\n",
      "Epoch 11/20\n",
      "149/149 [==============================] - 31s 207ms/step - loss: 0.4713 - accuracy: 0.8248 - val_loss: 0.7519 - val_accuracy: 0.7778\n",
      "Epoch 12/20\n",
      "149/149 [==============================] - 31s 208ms/step - loss: 0.4306 - accuracy: 0.8518 - val_loss: 0.6618 - val_accuracy: 0.7828\n",
      "Epoch 13/20\n",
      "149/149 [==============================] - 31s 209ms/step - loss: 0.4416 - accuracy: 0.8261 - val_loss: 0.7920 - val_accuracy: 0.7677\n",
      "Epoch 14/20\n",
      "149/149 [==============================] - 30s 199ms/step - loss: 0.4147 - accuracy: 0.8383 - val_loss: 0.8642 - val_accuracy: 0.7475\n",
      "Epoch 15/20\n",
      "149/149 [==============================] - 31s 209ms/step - loss: 0.3917 - accuracy: 0.8531 - val_loss: 0.8662 - val_accuracy: 0.7879\n",
      "Epoch 16/20\n",
      "149/149 [==============================] - 31s 208ms/step - loss: 0.3508 - accuracy: 0.8652 - val_loss: 1.2722 - val_accuracy: 0.7172\n",
      "Epoch 17/20\n",
      "149/149 [==============================] - 31s 208ms/step - loss: 0.3357 - accuracy: 0.8585 - val_loss: 0.9878 - val_accuracy: 0.7374\n",
      "Epoch 18/20\n",
      "149/149 [==============================] - 31s 207ms/step - loss: 0.3271 - accuracy: 0.8747 - val_loss: 1.2934 - val_accuracy: 0.6818\n",
      "Epoch 19/20\n",
      "149/149 [==============================] - 31s 209ms/step - loss: 0.3405 - accuracy: 0.8922 - val_loss: 1.1338 - val_accuracy: 0.7071\n",
      "Epoch 20/20\n",
      "149/149 [==============================] - 31s 208ms/step - loss: 0.3629 - accuracy: 0.8504 - val_loss: 0.7408 - val_accuracy: 0.7980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f6cba70aeb0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(\n",
    "        generator=x_train,steps_per_epoch = len(x_train),\n",
    "        epochs=20, validation_data=x_test,validation_steps = len(x_test))# No of images in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7165784",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fa516f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19bda4e4",
   "metadata": {},
   "source": [
    "# Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbb50055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "classifier.save('disaster.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "italian-typing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "disaster.h5\r\n"
     ]
    }
   ],
   "source": [
    "!tar -zcvf natural-disaster-classifier_new.tgz disaster.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "vietnamese-restaurant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mdataset\u001b[0m/\r\n",
      "disaster.h5\r\n",
      "model-bw.json\r\n",
      "natural-disaster-classifier_new.tgz\r\n"
     ]
    }
   ],
   "source": [
    "ls -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "black-advocate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting watson-machine-learning-client\n",
      "  Downloading watson_machine_learning_client-1.0.391-py3-none-any.whl (538 kB)\n",
      "\u001b[K     |████████████████████████████████| 538 kB 26.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (2.25.1)\n",
      "Requirement already satisfied: lomond in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (0.3.3)\n",
      "Requirement already satisfied: ibm-cos-sdk in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (2.7.0)\n",
      "Requirement already satisfied: urllib3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (1.26.6)\n",
      "Requirement already satisfied: tabulate in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (0.8.9)\n",
      "Requirement already satisfied: boto3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (1.17.46)\n",
      "Requirement already satisfied: certifi in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (2021.10.8)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (4.59.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from watson-machine-learning-client) (1.2.4)\n",
      "Requirement already satisfied: botocore<1.21.0,>=1.20.46 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from boto3->watson-machine-learning-client) (1.20.88)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from boto3->watson-machine-learning-client) (0.3.6)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from boto3->watson-machine-learning-client) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from botocore<1.21.0,>=1.20.46->boto3->watson-machine-learning-client) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.46->boto3->watson-machine-learning-client) (1.15.0)\n",
      "Requirement already satisfied: ibm-cos-sdk-core==2.7.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.7.0)\n",
      "Requirement already satisfied: ibm-cos-sdk-s3transfer==2.7.0 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.7.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from ibm-cos-sdk-core==2.7.0->ibm-cos-sdk->watson-machine-learning-client) (0.15.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests->watson-machine-learning-client) (2.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from requests->watson-machine-learning-client) (3.0.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pandas->watson-machine-learning-client) (2021.1)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages (from pandas->watson-machine-learning-client) (1.18.5)\n",
      "Installing collected packages: watson-machine-learning-client\n",
      "Successfully installed watson-machine-learning-client-1.0.391\n"
     ]
    }
   ],
   "source": [
    "#To save our file in machine learning repository we have to import library\n",
    "!pip install watson-machine-learning-client --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "behavioral-russell",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace the credentials that you got from watson Machine Learning Service\n",
    "from ibm_watson_machine_learning import APIClient\n",
    "wml_credentials = {\n",
    "                   \"url\":\"https://us-south.ml.cloud.ibm.com\",\n",
    "                   \"apikey\":\"msSVl1ItE8WsNE-qN6DCjR__9IvD8xCx3U4Py3Oq2-rk\"\n",
    "                  }\n",
    "client=APIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "injured-upgrade",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = APIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "alpha-publisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guid_from_space_name(client, space_name):\n",
    "    space = client.spaces.get_details()\n",
    "    #print(space)\n",
    "    return(next(item for item in space['resources'] if item['entity'][\"name\"] == space_name)['metadata']['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "following-brunswick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Space UID = 69d9ecd9-c6a9-48d3-856e-baf6ea02a14d\n"
     ]
    }
   ],
   "source": [
    "space_uid = guid_from_space_name(client, 'naturaldisaster1')\n",
    "print(\"Space UID = \" + space_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "foreign-parameter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.set.default_space(space_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "skilled-captain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------  ------------------------------------  ----\n",
      "NAME                           ASSET_ID                              TYPE\n",
      "default_py3.6                  0062b8c9-8b7d-44a0-a9b9-46c416adcbd9  base\n",
      "pytorch-onnx_1.3-py3.7-edt     069ea134-3346-5748-b513-49120e15d288  base\n",
      "scikit-learn_0.20-py3.6        09c5a1d0-9c1e-4473-a344-eb7b665ff687  base\n",
      "spark-mllib_3.0-scala_2.12     09f4cff0-90a7-5899-b9ed-1ef348aebdee  base\n",
      "ai-function_0.1-py3.6          0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda  base\n",
      "shiny-r3.6                     0e6e79df-875e-4f24-8ae9-62dcc2148306  base\n",
      "tensorflow_2.4-py3.7-horovod   1092590a-307d-563d-9b62-4eb7d64b3f22  base\n",
      "pytorch_1.1-py3.6              10ac12d6-6b30-4ccd-8392-3e922c096a92  base\n",
      "tensorflow_1.15-py3.6-ddl      111e41b3-de2d-5422-a4d6-bf776828c4b7  base\n",
      "scikit-learn_0.22-py3.6        154010fa-5b3b-4ac1-82af-4d5ee5abbc85  base\n",
      "default_r3.6                   1b70aec3-ab34-4b87-8aa0-a4a3c8296a36  base\n",
      "pytorch-onnx_1.3-py3.6         1bc6029a-cc97-56da-b8e0-39c3880dbbe7  base\n",
      "tensorflow_2.1-py3.6           1eb25b84-d6ed-5dde-b6a5-3fbdf1665666  base\n",
      "tensorflow_2.4-py3.8-horovod   217c16f6-178f-56bf-824a-b19f20564c49  base\n",
      "do_py3.8                       295addb5-9ef9-547e-9bf4-92ae3563e720  base\n",
      "autoai-ts_3.8-py3.8            2aa0c932-798f-5ae9-abd6-15e0c2402fb5  base\n",
      "tensorflow_1.15-py3.6          2b73a275-7cbf-420b-a912-eae7f436e0bc  base\n",
      "pytorch_1.2-py3.6              2c8ef57d-2687-4b7d-acce-01f94976dac1  base\n",
      "spark-mllib_2.3                2e51f700-bca0-4b0d-88dc-5c6791338875  base\n",
      "pytorch-onnx_1.1-py3.6-edt     32983cea-3f32-4400-8965-dde874a8d67e  base\n",
      "spark-mllib_3.0-py37           36507ebe-8770-55ba-ab2a-eafe787600e9  base\n",
      "spark-mllib_2.4                390d21f8-e58b-4fac-9c55-d7ceda621326  base\n",
      "xgboost_0.82-py3.6             39e31acd-5f30-41dc-ae44-60233c80306e  base\n",
      "pytorch-onnx_1.2-py3.6-edt     40589d0e-7019-4e28-8daa-fb03b6f4fe12  base\n",
      "autoai-obm_3.0                 42b92e18-d9ab-567f-988a-4240ba1ed5f7  base\n",
      "spark-mllib_2.4-r_3.6          49403dff-92e9-4c87-a3d7-a42d0021c095  base\n",
      "xgboost_0.90-py3.6             4ff8d6c2-1343-4c18-85e1-689c965304d3  base\n",
      "pytorch-onnx_1.1-py3.6         50f95b2a-bc16-43bb-bc94-b0bed208c60b  base\n",
      "autoai-ts_3.9-py3.8            52c57136-80fa-572e-8728-a5e7cbb42cde  base\n",
      "spark-mllib_2.4-scala_2.11     55a70f99-7320-4be5-9fb9-9edb5a443af5  base\n",
      "spark-mllib_3.0                5c1b0ca2-4977-5c2e-9439-ffd44ea8ffe9  base\n",
      "autoai-obm_2.0                 5c2e37fa-80b8-5e77-840f-d912469614ee  base\n",
      "spss-modeler_18.1              5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b  base\n",
      "cuda-py3.8                     5d3232bf-c86b-5df4-a2cd-7bb870a1cd4e  base\n",
      "autoai-kb_3.1-py3.7            632d4b22-10aa-5180-88f0-f52dfb6444d7  base\n",
      "pytorch-onnx_1.7-py3.8         634d3cdc-b562-5bf9-a2d4-ea90a478456b  base\n",
      "spark-mllib_2.3-r_3.6          6586b9e3-ccd6-4f92-900f-0f8cb2bd6f0c  base\n",
      "tensorflow_2.4-py3.7           65e171d7-72d1-55d9-8ebb-f813d620c9bb  base\n",
      "spss-modeler_18.2              687eddc9-028a-4117-b9dd-e57b36f1efa5  base\n",
      "pytorch-onnx_1.2-py3.6         692a6a4d-2c4d-45ff-a1ed-b167ee55469a  base\n",
      "do_12.9                        75a3a4b0-6aa0-41b3-a618-48b1f56332a6  base\n",
      "spark-mllib_2.3-scala_2.11     7963efe5-bbec-417e-92cf-0574e21b4e8d  base\n",
      "spark-mllib_2.4-py37           7abc992b-b685-532b-a122-a396a3cdbaab  base\n",
      "caffe_1.0-py3.6                7bb3dbe2-da6e-4145-918d-b6d84aa93b6b  base\n",
      "pytorch-onnx_1.7-py3.7         812c6631-42b7-5613-982b-02098e6c909c  base\n",
      "cuda-py3.6                     82c79ece-4d12-40e6-8787-a7b9e0f62770  base\n",
      "tensorflow_1.15-py3.6-horovod  8964680e-d5e4-5bb8-919b-8342c6c0dfd8  base\n",
      "hybrid_0.1                     8c1a58c6-62b5-4dc4-987a-df751c2756b6  base\n",
      "pytorch-onnx_1.3-py3.7         8d5d8a87-a912-54cf-81ec-3914adaa988d  base\n",
      "caffe-ibm_1.0-py3.6            8d863266-7927-4d1e-97d7-56a7f4c0a19b  base\n",
      "-----------------------------  ------------------------------------  ----\n",
      "Note: Only first 50 records were displayed. To display more use 'limit' parameter.\n"
     ]
    }
   ],
   "source": [
    "client.software_specifications.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "pressed-passion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2b73a275-7cbf-420b-a912-eae7f436e0bc'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "software_spec_uid = client.software_specifications.get_uid_by_name(\"tensorflow_1.15-py3.6\")\n",
    "software_spec_uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "appropriate-comparative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: Warnings!! :  Model type keras_2.2.4 is deprecated. We recommend you use a supported model type. See Supported Frameworks https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/pm_service_supported_frameworks.html\n"
     ]
    }
   ],
   "source": [
    "model_details = client.repository.store_model(model='natural-disaster-classifier_new.tgz',meta_props={\n",
    "client.repository.ModelMetaNames.NAME:\"CNN\",\n",
    "client.repository.ModelMetaNames.TYPE:\"keras_2.2.4\",\n",
    "client.repository.ModelMetaNames.SOFTWARE_SPEC_UID:software_spec_uid}\n",
    "                                             )\n",
    "model_id = client.repository.get_model_uid(model_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "28de2822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cf70fd82-d094-4cfa-b7b5-f876d3db13f3'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f456c2af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved model content to file: 'my_model1.tar.gz'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/wsuser/work/my_model1.tar.gz'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.repository.download(model_id, 'my_model1.tar.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b0c47c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6f925f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = classifier.to_json()\n",
    "with open(\"model-bw.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60affc33",
   "metadata": {},
   "source": [
    "# Predicting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f05b455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from keras.preprocessing import image\n",
    "model = load_model(\"disaster.h5\") #loading the model for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9e57e2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "streaming_body_2 = client_d6c4aa54985d4755b8f33ab78c4fe1f0.get_object(Bucket='naturaldisaster-donotdelete-pr-aj3prbxphtojo0', Key='cyclone.jpg')['Body']\n",
    "\n",
    "# Your data file was loaded into a botocore.response.StreamingBody object.\n",
    "# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n",
    "# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n",
    "# pandas documentation: http://pandas.pydata.org/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2770305b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not StreamingBody",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-86cf45267c57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# pandas documentation: http://pandas.pydata.org/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstreaming_body_3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#loading of the image\\n\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages/tensorflow/python/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    298\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msupported\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m   \"\"\"\n\u001b[0;32m--> 300\u001b[0;31m   return image.load_img(path, grayscale=grayscale, color_mode=color_mode,\n\u001b[0m\u001b[1;32m    301\u001b[0m                         target_size=target_size, interpolation=interpolation)\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/envs/Python-3.8-main/lib/python3.8/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not StreamingBody"
     ]
    }
   ],
   "source": [
    "\n",
    "streaming_body_3 = client_d6c4aa54985d4755b8f33ab78c4fe1f0.get_object(Bucket='naturaldisaster-donotdelete-pr-aj3prbxphtojo0', Key='cyclone.jpg')['Body']\n",
    "\n",
    "# Your data file was loaded into a botocore.response.StreamingBody object.\n",
    "# Please read the documentation of ibm_boto3 and pandas to learn more about the possibilities to load the data.\n",
    "# ibm_boto3 documentation: https://ibm.github.io/ibm-cos-sdk-python/\n",
    "# pandas documentation: http://pandas.pydata.org/\n",
    "img = image.load_img(streaming_body_3,target_size = (64,64))#loading of the image\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fcbb00fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x = image.img_to_array(img)\n",
    "x = np.expand_dims(x,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "308042b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_classes(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a3619e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c1d885cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cyclone'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=['Cyclone','Earthquake','Flood','Wildfire']\n",
    "result=str(index[pred[0]])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f77d2631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jupyterthemes\n",
      "  Using cached jupyterthemes-0.20.0-py2.py3-none-any.whl (7.0 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement as\n",
      "ERROR: No matching distribution found for as\n"
     ]
    }
   ],
   "source": [
    "!pip install jupyterthemes as jt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b84e2478",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'jt' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!jt -t monokai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f4196f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
